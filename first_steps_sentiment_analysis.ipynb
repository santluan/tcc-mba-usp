{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99443e55",
   "metadata": {},
   "source": [
    "# Primeiros Passos - Análise de Sentimentos com Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d268c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf3bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o conjunto de dados de \n",
    "data = pd.read_csv('D:\\\\Desktop\\\\DataScience\\\\mba\\\\tcc\\\\financial_sentences.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0603a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbe3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semente aleatório apara reprodutibilidade\n",
    "np.random.seed(7542)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725762e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['Sentence']\n",
    "y = data['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c85d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonte: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=['negative', 'neutral', 'positive'],\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc4b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Accuracy: (Correct / Total)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "# Precision\n",
    "prec = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Precision: {prec}\")\n",
    "\n",
    "# Recall\n",
    "rec = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Recall: {rec}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a71952",
   "metadata": {},
   "source": [
    "# Pré-processamento dos dados\n",
    "\n",
    "Aplicar as etapas de pré-processamento aos dados para melhoria do modelo  \n",
    "1- Lowercasing  \n",
    "2- Remoção de pontuação  \n",
    "3- Tokenização  \n",
    "4- Remoção de stopwords  \n",
    "5- Stemming  \n",
    "6- Lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e671d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
